{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ae3d03-5191-4780-9998-a3c43f02d8c6",
   "metadata": {},
   "source": [
    "## Load the data onto a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd9941d-bad5-4e38-b8b2-5a0512c7396d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca0adf5-0e41-4f7f-8d68-69e3e4c75ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined_dataset_with_binary_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "512abca2-0824-4423-abfe-1af446fb8905",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate through the 'MFCC_Features' column in the DataFrame\n",
    "for index, input_string in enumerate(df['MFCC_Features']):\n",
    "    # Remove the square brackets\n",
    "    input_string = input_string.strip('[]')\n",
    "    \n",
    "    # Split the string by whitespace and convert to floats\n",
    "    float_list = [float(val) for val in input_string.split() if val.strip()]\n",
    "    \n",
    "    # Update the 'MFCC_Features' column with the list of floats for the current row\n",
    "    df.at[index, 'MFCC_Features'] = float_list\n",
    "    \n",
    "df['MFCC_Features']\n",
    "\n",
    "# Split the 'MFCC_Features' column into separate columns\n",
    "df[['MFCC_Feature_1', 'MFCC_Feature_2', 'MFCC_Feature_3', 'MFCC_Feature_4',\n",
    "    'MFCC_Feature_5', 'MFCC_Feature_6', 'MFCC_Feature_7', 'MFCC_Feature_8',\n",
    "    'MFCC_Feature_9', 'MFCC_Feature_10', 'MFCC_Feature_11', 'MFCC_Feature_12',\n",
    "    'MFCC_Feature_13']] = pd.DataFrame(df['MFCC_Features'].tolist(), index=df.index)\n",
    "\n",
    "df;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b335b0c-46ef-40be-acec-4da671f66568",
   "metadata": {},
   "source": [
    "## Using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2744bc03-4b1c-49bb-b67e-1fe21c359803",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split data into features (X) and the target variable (y)\n",
    "X = df[['MFCC_Feature_1', 'MFCC_Feature_2', 'MFCC_Feature_3', 'MFCC_Feature_4',\n",
    "        'MFCC_Feature_5', 'MFCC_Feature_6', 'MFCC_Feature_7', 'MFCC_Feature_8',\n",
    "        'MFCC_Feature_9', 'MFCC_Feature_10', 'MFCC_Feature_11', 'MFCC_Feature_12',\n",
    "        'MFCC_Feature_13']]\n",
    "# print(X)\n",
    "\n",
    "y = df['Alzheimer_Status']\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1bd9b5-f2a4-4d7c-bb52-83103f6d8302",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0acdda11-cbd1-43f9-81fe-e704bbef7150",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into a training set and a testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3743642-cc42-4621-bb20-36552dfd45fe",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78b1d5a9-0a89-4dd9-8ada-461fc3993739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pickle import dump\n",
    "from pickle import load\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b892c3ac-bd82-4a22-a66c-d1afed62c5f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [50,100,150,200,250,300,350,400,450,500,700,1000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth' : [1,2,3,4,5,6,7,8,9,10], 'criterion' :['entropy', 'gini']}\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac108ad2-aa5a-4501-8f47-ea1bf00de951",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "2400 fits failed out of a total of 7200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.59298246 0.58245614 0.53976608 0.56608187 0.55643275 0.54532164\n",
      " 0.54502924 0.56725146 0.57192982 0.56081871 0.57719298 0.55584795\n",
      " 0.56169591 0.55555556 0.57163743 0.56666667 0.56052632 0.57719298\n",
      " 0.57719298 0.56140351 0.57163743 0.56111111 0.57163743 0.56140351\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.58216374 0.56111111 0.57690058 0.56608187 0.56637427 0.5877193\n",
      " 0.57719298 0.57192982 0.56666667 0.54532164 0.57690058 0.59795322\n",
      " 0.58830409 0.5877193  0.57690058 0.57690058 0.57690058 0.56111111\n",
      " 0.58245614 0.59298246 0.5874269  0.5874269  0.57690058 0.5874269\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.62953216 0.59766082 0.60350877 0.60321637 0.59269006 0.61403509\n",
      " 0.59298246 0.5874269  0.60321637 0.59298246 0.58216374 0.5874269\n",
      " 0.59824561 0.58245614 0.58830409 0.60877193 0.59298246 0.58245614\n",
      " 0.60380117 0.61403509 0.60906433 0.59298246 0.59269006 0.59298246\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.5994152  0.60906433 0.59853801 0.5877193  0.59795322 0.61432749\n",
      " 0.5874269  0.60350877 0.60877193 0.59824561 0.60350877 0.61432749\n",
      " 0.60438596 0.6245614  0.5874269  0.63040936 0.60380117 0.60409357\n",
      " 0.59824561 0.61461988 0.60877193 0.60350877 0.59853801 0.5877193\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.61929825 0.60877193 0.60877193 0.61432749 0.60877193 0.61988304\n",
      " 0.60380117 0.59298246 0.61403509 0.59824561 0.60906433 0.61432749\n",
      " 0.57192982 0.6248538  0.59298246 0.63011696 0.59795322 0.60380117\n",
      " 0.63011696 0.63011696 0.60877193 0.61959064 0.61959064 0.60350877\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.56608187 0.5871345  0.63596491 0.63538012 0.61959064 0.61374269\n",
      " 0.61959064 0.6248538  0.63011696 0.63011696 0.6245614  0.61929825\n",
      " 0.62426901 0.65087719 0.63040936 0.60877193 0.61929825 0.63040936\n",
      " 0.61959064 0.61929825 0.61403509 0.6248538  0.61374269 0.61929825\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.6245614  0.63011696 0.6251462  0.61432749 0.59327485 0.64064327\n",
      " 0.6245614  0.61403509 0.62982456 0.6245614  0.61959064 0.6251462\n",
      " 0.61929825 0.63040936 0.59795322 0.61929825 0.62982456 0.61403509\n",
      " 0.62982456 0.64064327 0.61959064 0.64064327 0.63567251 0.61959064\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.61929825 0.6245614  0.61871345 0.61900585 0.63479532 0.60321637\n",
      " 0.61929825 0.63011696 0.63508772 0.61461988 0.6251462  0.62982456\n",
      " 0.60906433 0.64590643 0.62426901 0.61374269 0.63508772 0.63538012\n",
      " 0.60877193 0.61929825 0.61959064 0.63011696 0.61432749 0.61929825\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.63040936 0.60847953 0.6245614  0.61403509 0.6248538  0.59824561\n",
      " 0.61374269 0.64035088 0.65116959 0.64064327 0.62982456 0.62426901\n",
      " 0.60350877 0.62982456 0.61929825 0.61345029 0.64590643 0.61959064\n",
      " 0.63479532 0.64561404 0.62982456 0.63508772 0.63538012 0.61929825\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.5871345  0.61374269 0.62426901 0.6245614  0.64064327 0.62982456\n",
      " 0.60321637 0.6245614  0.60877193 0.60877193 0.61959064 0.62982456\n",
      " 0.60350877 0.61403509 0.63538012 0.6245614  0.64064327 0.60847953\n",
      " 0.65116959 0.60847953 0.60877193 0.6251462  0.60877193 0.61959064\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.57163743 0.57660819 0.53421053 0.54444444 0.56608187 0.53976608\n",
      " 0.56637427 0.55555556 0.56637427 0.56081871 0.56608187 0.57134503\n",
      " 0.57719298 0.56608187 0.55526316 0.56081871 0.5502924  0.56666667\n",
      " 0.55555556 0.56111111 0.54502924 0.57192982 0.56608187 0.57163743\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.57719298 0.57690058 0.56637427 0.58187135 0.5871345  0.59269006\n",
      " 0.56111111 0.58245614 0.59269006 0.5874269  0.58216374 0.59269006\n",
      " 0.58216374 0.60877193 0.57134503 0.5877193  0.57134503 0.55584795\n",
      " 0.56608187 0.58216374 0.5874269  0.58216374 0.59795322 0.57163743\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.58187135 0.56637427 0.5874269  0.60350877 0.59795322 0.60847953\n",
      " 0.59766082 0.59269006 0.59795322 0.5874269  0.60847953 0.60321637\n",
      " 0.58245614 0.5874269  0.56608187 0.59795322 0.59269006 0.60847953\n",
      " 0.58216374 0.60847953 0.5874269  0.61374269 0.60350877 0.60847953\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.59766082 0.59269006 0.60292398 0.61959064 0.59824561 0.63508772\n",
      " 0.60350877 0.61432749 0.61403509 0.61403509 0.63011696 0.6248538\n",
      " 0.60906433 0.60847953 0.57660819 0.59766082 0.60380117 0.61988304\n",
      " 0.60350877 0.5874269  0.61374269 0.59795322 0.60906433 0.60847953\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.61900585 0.61461988 0.60906433 0.61900585 0.59269006 0.59824561\n",
      " 0.6248538  0.61959064 0.60877193 0.61929825 0.60321637 0.6248538\n",
      " 0.6245614  0.60877193 0.63011696 0.60906433 0.63538012 0.61345029\n",
      " 0.61403509 0.60350877 0.60877193 0.60906433 0.60847953 0.60877193\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.61432749 0.62982456 0.61959064 0.6245614  0.60906433 0.61461988\n",
      " 0.61959064 0.61432749 0.60380117 0.6245614  0.62426901 0.61461988\n",
      " 0.58216374 0.61929825 0.60350877 0.61900585 0.6245614  0.64064327\n",
      " 0.61403509 0.60350877 0.63011696 0.6248538  0.6251462  0.61959064\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.55       0.61900585 0.60877193 0.60292398 0.61959064 0.61959064\n",
      " 0.60350877 0.59795322 0.61900585 0.63011696 0.60906433 0.64093567\n",
      " 0.60877193 0.59853801 0.64035088 0.61929825 0.61871345 0.62982456\n",
      " 0.61959064 0.61929825 0.61959064 0.60321637 0.60847953 0.60877193\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.60350877 0.61403509 0.63011696 0.60350877 0.6248538  0.62982456\n",
      " 0.60847953 0.61432749 0.61959064 0.61929825 0.61959064 0.61900585\n",
      " 0.61959064 0.63011696 0.6245614  0.60877193 0.62982456 0.64035088\n",
      " 0.61900585 0.63567251 0.6248538  0.61959064 0.61988304 0.6251462\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.60935673 0.65672515 0.62426901 0.65116959 0.59824561 0.59824561\n",
      " 0.61403509 0.6245614  0.63538012 0.61988304 0.59795322 0.60877193\n",
      " 0.59824561 0.61432749 0.62982456 0.6251462  0.61432749 0.62982456\n",
      " 0.61929825 0.61432749 0.59824561 0.63011696 0.60350877 0.60877193\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.6505848  0.63508772 0.61403509 0.61374269 0.63479532 0.59298246\n",
      " 0.6251462  0.62953216 0.61929825 0.63011696 0.61929825 0.60906433\n",
      " 0.6245614  0.6248538  0.61374269 0.57690058 0.63508772 0.63011696\n",
      " 0.61403509 0.60350877 0.60380117 0.61403509 0.61403509 0.59795322]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loocv = LeaveOneOut()\n",
    "scoring = 'accuracy'\n",
    "kfold = KFold(n_splits=10, random_state=None)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797eb466-8f02-47ed-83e4-c2382909ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa4a03e-6b1a-40f6-ac65-570f56b776d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_result.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "filename = 'GFCC_German_A_RF1.sav'\n",
    "dump(best_model,open(filename, 'wb'))\n",
    "loaded_model = load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a99b0-609b-4e1b-9e8a-9b54e14c4629",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = loaded_model.predict(X_test)\n",
    "MCC=matthews_corrcoef(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f777d3e4-cc98-4a19-8cb9-29e8e6f77543",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm1 = confusion_matrix(y_test, y_pred1)\n",
    "acc = (cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[0,1]+cm1[1,0]+cm1[1,1])\n",
    "spec = (cm1[0,0])/(cm1[0,0]+cm1[0,1])\n",
    "sens = (cm1[1,1])/(cm1[1,0]+cm1[1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d95918e-760f-419b-b35a-fc4234878eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Testing Accuracy =' ,acc)\n",
    "print('Testing Sensitivity(abnormality) =' ,sens)\n",
    "print('Testing Specificity(normality) =' ,spec)\n",
    "print ('confusion matrix =', cm1)\n",
    "print ('MCC Score =', MCC)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5c2a7-c2d9-4961-a0e9-fad09ef9a9f1",
   "metadata": {},
   "source": [
    "## Using Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "7fab4b9b-d2d4-4bc2-8aa6-679d43380c25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb0f5e3-d870-408d-b145-850b4df01379",
   "metadata": {},
   "source": [
    "### Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "235396da-ec0d-4943-828a-6b5f261b1ede",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear', C=1.0)\n",
    "svm_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c3729251-9778-4374-b22c-219e5e62776b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_svm = svm_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f411541a-775c-48ad-a918-fdd55de01b01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (SVM): 0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.50      0.52        22\n",
      "           1       0.61      0.65      0.63        26\n",
      "\n",
      "    accuracy                           0.58        48\n",
      "   macro avg       0.58      0.58      0.58        48\n",
      "weighted avg       0.58      0.58      0.58        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "report_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "print(f'Accuracy (SVM): {accuracy_svm}')\n",
    "print(report_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f5315-75f4-4c3e-b601-b3115b454b36",
   "metadata": {},
   "source": [
    "### Radial Basis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e1279ade-41b8-4c84-91ee-484d1dbe277f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-23 {color: black;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model = SVC(kernel='rbf', C=1.0)\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "31d8c3f3-27e7-4a4d-99b3-c3f874ea4fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_svm = svm_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ba513ab4-fbba-42d7-8e45-d110b9c63005",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (SVM): 0.5416666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.14      0.21        22\n",
      "           1       0.55      0.88      0.68        26\n",
      "\n",
      "    accuracy                           0.54        48\n",
      "   macro avg       0.52      0.51      0.45        48\n",
      "weighted avg       0.53      0.54      0.46        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "report_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "print(f'Accuracy (SVM): {accuracy_svm}')\n",
    "print(report_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12f66f-9adf-4078-8057-539779665b19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
